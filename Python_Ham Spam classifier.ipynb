{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_NLP_practice_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpiWx_B4H2dQ",
        "outputId": "6ff7733e-a091-4362-bbc7-53c0c27d9bbb"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('punkt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBmKCOo6IsoN"
      },
      "source": [
        "df_data=pd.DataFrame([{'Text': 'reading assignment', 'Label':'Ham'}, \n",
        "                      {'Text': 'analysis and design assignment', 'Label':'Ham'}, \n",
        "                      {'Text': 'hello how are you', 'Label':'Ham'}, \n",
        "                      {'Text': 'requirements analysis', 'Label':'Ham'}, \n",
        "                      {'Text': 'win free', 'Label':'Spam'}, \n",
        "                      {'Text': 'lotto millions', 'Label':'Spam'}, \n",
        "                      {'Text': 'win win win millions', 'Label':'Spam'},\n",
        "                      {'Text': 'free offers', 'Label':'Spam'}])\n",
        "df_data_ham=df_data[df_data.Label=='Ham']\n",
        "df_data_spam=df_data[df_data.Label=='Spam']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7N_Xf8XJgzZ",
        "outputId": "ea23f514-9f0b-4ce6-ed78-fbba558f2012"
      },
      "source": [
        "#TDM(Term Document Frequency): all emails\n",
        "vec=CountVectorizer()\n",
        "tdf=vec.fit_transform(df_data['Text'])\n",
        "total_words=len(vec.get_feature_names())\n",
        "\n",
        "#TDM: ham\n",
        "count_vec_ham=CountVectorizer()\n",
        "tdf_ham=count_vec_ham.fit_transform(df_data_ham['Text'])\n",
        "tdm_ham=pd.DataFrame(tdf_ham.toarray(), columns=count_vec_ham.get_feature_names())\n",
        "word_list_ham=count_vec_ham.get_feature_names();\n",
        "tdm_ham_dict=dict(zip(word_list_ham, tdf_ham.toarray().sum(axis=0)))\n",
        "print(tdm_ham_dict)\n",
        "\n",
        "#TDM: spam \n",
        "count_vect_spam = CountVectorizer() \n",
        "tdf_spam = count_vect_spam.fit_transform(df_data_spam['Text']) \n",
        "tdm_spam = pd.DataFrame(tdf_spam.toarray(), columns=count_vect_spam.get_feature_names()) \n",
        "word_list_spam = count_vect_spam.get_feature_names(); \n",
        "tdm_spam_dict = dict(zip(word_list_spam, tdf_spam.toarray().sum(axis=0) )) \n",
        "print(tdm_spam_dict)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'analysis': 2, 'and': 1, 'are': 1, 'assignment': 2, 'design': 1, 'hello': 1, 'how': 1, 'reading': 1, 'requirements': 1, 'you': 1}\n",
            "{'free': 2, 'lotto': 1, 'millions': 2, 'offers': 1, 'win': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK6x8PTvO4IQ"
      },
      "source": [
        "#compute probability for ham and spam\n",
        "prior_prob_spam = df_data_spam.shape[0] / df_data.shape[0]\n",
        "prior_prob_ham = df_data_ham.shape[0] / df_data.shape[0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRnfrZQCRyyf"
      },
      "source": [
        "#calculate posterior probability \n",
        "def post_prob(test_sentence):\n",
        "\n",
        "  prob_spam_all_words=1\n",
        "  prob_ham_all_words=1\n",
        "\n",
        "  ham_words_count=tdf_ham.toarray().sum()\n",
        "  spam_words_count=tdf_spam.toarray().sum()\n",
        "\n",
        "#P(word|spam)\n",
        "  words=word_tokenize(test_sentence)\n",
        "  for word in words:\n",
        "    prob_spam_word=((tdm_spam_dict.get(word, 0) + 1) / (spam_words_count+total_words))\n",
        "    prob_spam_all_words=prob_spam_all_words * prob_spam_word\n",
        "\n",
        "    #P(word|ham)\n",
        "    prob_ham_word = ((tdm_ham_dict.get(word, 0) + 1) / (ham_words_count + total_words))\n",
        "    prob_ham_all_words = prob_ham_all_words * prob_ham_word\n",
        "\n",
        "    # P(ham|words) = P(ham) * P(words|ham) \n",
        "    posterior_ham = prior_prob_ham * prob_ham_all_words \n",
        "    # P(spam|words) = P(spam) * P(words|spam) \n",
        "    posterior_spam = prior_prob_spam * prob_spam_all_words\n",
        "\n",
        "    CLASS = 'ham' if posterior_ham > posterior_spam else 'spam'\n",
        "\n",
        "    # prob \n",
        "    prob_ham = posterior_ham / (posterior_spam + posterior_ham) \n",
        "    prob_spam = posterior_spam / (posterior_spam + posterior_ham) \n",
        "    return (prob_ham, prob_spam, CLASS)\n",
        "\n",
        "    prob_ham, prob_spam, c = posterior_prob(test_sentence='free deal') \n",
        "    print(prob_ham, prob_spam, c)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}